{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark with Movielens dataset\n",
    "\n",
    "This illustrative comparison applies to collaborative filtering algorithms available in this repository such as Spark ALS, Surprise SVD, SAR and others using the Movielens dataset. These algorithms are usable in a variety of recommendation tasks, including product or news recommendations.\n",
    "\n",
    "The main purpose of this notebook is not to produce comprehensive benchmarking results on multiple datasets. Rather, it is intended to illustrate on how one could evaluate different recommender algorithms using tools in this repository.\n",
    "\n",
    "## Experimentation setup:\n",
    "\n",
    "* Objective\n",
    "  * To compare how each collaborative filtering algorithm perform in predicting ratings and recommending relevant items.\n",
    "\n",
    "* Environment\n",
    "  * The comparison is run on a [Azure Data Science Virtual Machine](https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/). \n",
    "  * The virtual machine size is Standard NC6 (6 vcpus, 55 GB memory, 1K80 GPU).\n",
    "  * It should be noted that the single node DSVM is not supposed to run scalable benchmarking analysis. Either scaling up or out the computing instances is necessary to run the benchmarking in an run-time efficient way without any memory issue.\n",
    "  * **NOTE ABOUT THE DEPENDENCIES TO INSTALL**: This notebook uses CPU, GPU and PySpark algorithms, so make sure you install the `full environment` as detailed in the [SETUP.md](../../SETUP.md). \n",
    "  \n",
    "* Datasets\n",
    "  * [Movielens 100K](https://grouplens.org/datasets/movielens/100k/).\n",
    "  * [Movielens 1M](https://grouplens.org/datasets/movielens/1m/).\n",
    "\n",
    "* Data split\n",
    "  * The data is split into train and test sets.\n",
    "  * The split ratios are 75-25 for train and test datasets.\n",
    "  * The splitting is stratified based on items. \n",
    "\n",
    "* Model training\n",
    "  * A recommendation model is trained by using each of the collaborative filtering algorithms. \n",
    "  * Empirical parameter values reported [here](http://mymedialite.net/examples/datasets.html) are used in this notebook.  More exhaustive hyper parameter tuning would be required to further optimize results.\n",
    "\n",
    "* Evaluation metrics\n",
    "  * Ranking metrics:\n",
    "    * Precision@k.\n",
    "    * Recall@k.\n",
    "    * Normalized discounted cumulative gain@k (NDCG@k).\n",
    "    * Mean-average-precision (MAP). \n",
    "    * In the evaluation metrics above, k = 10. \n",
    "  * Rating metrics:\n",
    "    * Root mean squared error (RMSE).\n",
    "    * Mean average error (MAE).\n",
    "    * R squared.\n",
    "    * Explained variance.\n",
    "  * Run time performance\n",
    "    * Elapsed for training a model and using a model for predicting/recommending k items. \n",
    "    * The time may vary across different machines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globals settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.8.5 (default, Sep  4 2020, 07:30:14) \n",
      "[GCC 7.3.0]\n",
      "Pandas version: 1.4.2\n",
      "PySpark version: 3.2.1\n",
      "Surprise version: 1.1.1\n",
      "PyTorch version: 1.9.0+cu111\n",
      "Fast AI version: 1.0.61\n",
      "Cornac version: 1.14.2\n",
      "Tensorflow version: 2.7.3\n",
      "CUDA version: No CUDA in this machine\n",
      "CuDNN version: 8.2.1\n",
      "Number of cores: 6\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pyspark\n",
    "import torch\n",
    "import fastai\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "import surprise\n",
    "\n",
    "from recommenders.utils.general_utils import get_number_processors\n",
    "from recommenders.utils.gpu_utils import get_cuda_version, get_cudnn_version\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_stratified_split\n",
    "from recommenders.models.fastai.fastai_utils import hide_fastai_progress_bar\n",
    "\n",
    "from benchmark_utils import * \n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"PySpark version: {}\".format(pyspark.__version__))\n",
    "print(\"Surprise version: {}\".format(surprise.__version__))\n",
    "print(\"PyTorch version: {}\".format(torch.__version__))\n",
    "print(\"Fast AI version: {}\".format(fastai.__version__))\n",
    "print(\"Cornac version: {}\".format(cornac.__version__))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n",
    "print(\"CUDA version: {}\".format(get_cuda_version()))\n",
    "print(\"CuDNN version: {}\".format(get_cudnn_version()))\n",
    "n_cores = get_number_processors()\n",
    "print(\"Number of cores: {}\".format(n_cores))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide fastai progress bar\n",
    "hide_fastai_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds to make sure out runs are reproducible\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "environments = {\n",
    "    \"als\": \"pyspark\",\n",
    "    \"sar\": \"python_cpu\",\n",
    "    \"svd\": \"python_cpu\",\n",
    "    \"fastai\": \"python_gpu\",\n",
    "    \"ncf\": \"python_gpu\",\n",
    "    \"bpr\": \"python_cpu\",\n",
    "    \"bivae\": \"python_gpu\",\n",
    "    \"lightgcn\": \"python_gpu\",\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"als\": [\"rating\", \"ranking\"],\n",
    "    \"sar\": [\"ranking\"],\n",
    "    \"svd\": [\"rating\", \"ranking\"],\n",
    "    \"fastai\": [\"rating\", \"ranking\"],\n",
    "    \"ncf\": [\"ranking\"],\n",
    "    \"bpr\": [\"ranking\"],\n",
    "    \"bivae\": [\"ranking\"],\n",
    "    \"lightgcn\": [\"ranking\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_params = {\n",
    "    \"rank\": 10,\n",
    "    \"maxIter\": 15,\n",
    "    \"implicitPrefs\": False,\n",
    "    \"alpha\": 0.1,\n",
    "    \"regParam\": 0.05,\n",
    "    \"coldStartStrategy\": \"drop\",\n",
    "    \"nonnegative\": False,\n",
    "    \"userCol\": DEFAULT_USER_COL,\n",
    "    \"itemCol\": DEFAULT_ITEM_COL,\n",
    "    \"ratingCol\": DEFAULT_RATING_COL,\n",
    "}\n",
    "\n",
    "sar_params = {\n",
    "    \"similarity_type\": \"jaccard\",\n",
    "    \"time_decay_coefficient\": 30,\n",
    "    \"time_now\": None,\n",
    "    \"timedecay_formula\": True,\n",
    "    \"col_user\": DEFAULT_USER_COL,\n",
    "    \"col_item\": DEFAULT_ITEM_COL,\n",
    "    \"col_rating\": DEFAULT_RATING_COL,\n",
    "    \"col_timestamp\": DEFAULT_TIMESTAMP_COL,\n",
    "}\n",
    "\n",
    "svd_params = {\n",
    "    \"n_factors\": 150,\n",
    "    \"n_epochs\": 15,\n",
    "    \"lr_all\": 0.005,\n",
    "    \"reg_all\": 0.02,\n",
    "    \"random_state\": SEED,\n",
    "    \"verbose\": False\n",
    "}\n",
    "\n",
    "fastai_params = {\n",
    "    \"n_factors\": 40, \n",
    "    \"y_range\": [0,5.5], \n",
    "    \"wd\": 1e-1,\n",
    "    \"max_lr\": 5e-3,\n",
    "    \"epochs\": 15\n",
    "}\n",
    "\n",
    "ncf_params = {\n",
    "    \"model_type\": \"NeuMF\",\n",
    "    \"n_factors\": 4,\n",
    "    \"layer_sizes\": [16, 8, 4],\n",
    "    \"n_epochs\": 15,\n",
    "    \"batch_size\": 1024,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"verbose\": 10\n",
    "}\n",
    "\n",
    "bpr_params = {\n",
    "    \"k\": 200,\n",
    "    \"max_iter\": 200,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"lambda_reg\": 1e-3,\n",
    "    \"seed\": SEED,\n",
    "    \"verbose\": False\n",
    "}\n",
    "\n",
    "bivae_params = {\n",
    "    \"k\": 100,\n",
    "    \"encoder_structure\": [200],\n",
    "    \"act_fn\": \"tanh\",\n",
    "    \"likelihood\": \"pois\",\n",
    "    \"n_epochs\": 500,\n",
    "    \"batch_size\": 1024,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"seed\": SEED,\n",
    "    \"use_gpu\": True,\n",
    "    \"verbose\": False\n",
    "}\n",
    "\n",
    "lightgcn_param = {\n",
    "    \"yaml_file\": os.path.join(\"..\",\"..\", \"recommenders\",\"models\",\"deeprec\", \"config\", \"lightgcn.yaml\"),\n",
    "    \"n_layers\": 3,\n",
    "    \"batch_size\": 1024,\n",
    "    \"epochs\": 15,\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"eval_epoch\": 5,\n",
    "    \"top_k\": DEFAULT_K,\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"als\": als_params,\n",
    "    \"sar\": sar_params,\n",
    "    \"svd\": svd_params,\n",
    "    \"fastai\": fastai_params,\n",
    "    \"ncf\": ncf_params,\n",
    "    \"bpr\": bpr_params,\n",
    "    \"bivae\": bivae_params,\n",
    "    \"lightgcn\": lightgcn_param,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_training_data = {\n",
    "    \"als\": prepare_training_als,\n",
    "    \"sar\": prepare_training_sar,\n",
    "    \"svd\": prepare_training_svd,\n",
    "    \"fastai\": prepare_training_fastai,\n",
    "    \"ncf\": prepare_training_ncf,\n",
    "    \"bpr\": prepare_training_cornac,\n",
    "    \"bivae\": prepare_training_cornac,\n",
    "    \"lightgcn\": prepare_training_lightgcn,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_metrics_data = {\n",
    "    \"als\": lambda train, test: prepare_metrics_als(train, test),\n",
    "    \"fastai\": lambda train, test: prepare_metrics_fastai(train, test),    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = {\n",
    "    \"als\": lambda params, data: train_als(params, data),\n",
    "    \"svd\": lambda params, data: train_svd(params, data),\n",
    "    \"sar\": lambda params, data: train_sar(params, data), \n",
    "    \"fastai\": lambda params, data: train_fastai(params, data),\n",
    "    \"ncf\": lambda params, data: train_ncf(params, data),\n",
    "    \"bpr\": lambda params, data: train_bpr(params, data),\n",
    "    \"bivae\": lambda params, data: train_bivae(params, data),\n",
    "    \"lightgcn\": lambda params, data: train_lightgcn(params, data),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_predictor = {\n",
    "    \"als\": lambda model, test: predict_als(model, test),\n",
    "    \"svd\": lambda model, test: predict_svd(model, test),\n",
    "    \"fastai\": lambda model, test: predict_fastai(model, test),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_predictor = {\n",
    "    \"als\": lambda model, test, train: recommend_k_als(model, test, train),\n",
    "    \"sar\": lambda model, test, train: recommend_k_sar(model, test, train),\n",
    "    \"svd\": lambda model, test, train: recommend_k_svd(model, test, train),\n",
    "    \"fastai\": lambda model, test, train: recommend_k_fastai(model, test, train),\n",
    "    \"ncf\": lambda model, test, train: recommend_k_ncf(model, test, train),\n",
    "    \"bpr\": lambda model, test, train: recommend_k_cornac(model, test, train),\n",
    "    \"bivae\": lambda model, test, train: recommend_k_cornac(model, test, train),\n",
    "    \"lightgcn\": lambda model, test, train: recommend_k_lightgcn(model, test, train),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_evaluator = {\n",
    "    \"als\": lambda test, predictions: rating_metrics_pyspark(test, predictions),\n",
    "    \"svd\": lambda test, predictions: rating_metrics_python(test, predictions),\n",
    "    \"fastai\": lambda test, predictions: rating_metrics_python(test, predictions)\n",
    "}\n",
    "    \n",
    "    \n",
    "ranking_evaluator = {\n",
    "    \"als\": lambda test, predictions, k: ranking_metrics_pyspark(test, predictions, k),\n",
    "    \"sar\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"svd\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"fastai\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"ncf\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"bpr\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"bivae\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"lightgcn\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(data, algo, k, train_time, time_rating, rating_metrics, time_ranking, ranking_metrics):\n",
    "    summary = {\"Data\": data, \"Algo\": algo, \"K\": k, \"Train time (s)\": train_time, \"Predicting time (s)\": time_rating, \"Recommending time (s)\": time_ranking}\n",
    "    if rating_metrics is None:\n",
    "        rating_metrics = {\n",
    "            \"RMSE\": np.nan,\n",
    "            \"MAE\": np.nan,\n",
    "            \"R2\": np.nan,\n",
    "            \"Explained Variance\": np.nan,\n",
    "        }\n",
    "    if ranking_metrics is None:\n",
    "        ranking_metrics = {\n",
    "            \"MAP\": np.nan,\n",
    "            \"nDCG@k\": np.nan,\n",
    "            \"Precision@k\": np.nan,\n",
    "            \"Recall@k\": np.nan,\n",
    "        }\n",
    "    summary.update(rating_metrics)\n",
    "    summary.update(ranking_metrics)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sizes = [\"100k\", \"1m\"] # Movielens data size: 100k, 1m, 10m, or 20m\n",
    "algorithms = [\"als\", \"svd\", \"sar\", \"ncf\", \"fastai\", \"bpr\", \"bivae\", \"lightgcn\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:recommenders.datasets.download_utils:Downloading https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
      "100%|██████████| 4.81k/4.81k [00:00<00:00, 18.9kKB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Movielens 100k: (100000, 4)\n",
      "\n",
      "Computing als algorithm on Movielens 100k\n",
      "Training time: 7.2316s\n",
      "Rating prediction time: 0.0861s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking prediction time: 0.0869s\n",
      "\n",
      "Computing svd algorithm on Movielens 100k\n",
      "Training time: 4.3036s\n",
      "Rating prediction time: 0.2510s\n",
      "Ranking prediction time: 14.3849s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Collecting user affinity matrix\n",
      "INFO:root:Calculating time-decayed affinities\n",
      "INFO:root:Creating index columns\n",
      "INFO:root:Building user affinity sparse matrix\n",
      "INFO:root:Calculating item co-occurrence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing sar algorithm on Movielens 100k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Calculating item similarity\n",
      "INFO:root:Using jaccard based similarity\n",
      "INFO:root:Done training\n",
      "INFO:root:Calculating recommendation scores\n",
      "INFO:root:Removing seen items\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.3554s\n",
      "Ranking prediction time: 0.0881s\n",
      "\n",
      "Computing ncf algorithm on Movielens 100k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:recommenders.models.ncf.dataset:Indexing ./df_train.csv ...\n",
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 10 [3.46s]: train_loss = 0.309075 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 52.1639s\n",
      "Ranking prediction time: 3.6720s\n",
      "\n",
      "Computing fastai algorithm on Movielens 100k\n",
      "Training time: 78.5280s\n",
      "Rating prediction time: 0.0444s\n",
      "Ranking prediction time: 3.0010s\n",
      "\n",
      "Computing bpr algorithm on Movielens 100k\n",
      "Training time: 6.1744s\n",
      "Ranking prediction time: 3.9153s\n",
      "\n",
      "Computing bivae algorithm on Movielens 100k\n",
      "Training time: 22.0689s\n",
      "Ranking prediction time: 1.5642s\n",
      "\n",
      "Computing lightgcn algorithm on Movielens 100k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/recommenders/models/deeprec/DataModel/ImplicitCF.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = train if test is None else train.append(test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n",
      "Epoch 1 (train)4.5s: train loss = 0.47628 = (mf)0.47604 + (embed)0.00024\n",
      "Epoch 2 (train)4.3s: train loss = 0.29379 = (mf)0.29316 + (embed)0.00063\n",
      "Epoch 3 (train)4.3s: train loss = 0.25659 = (mf)0.25579 + (embed)0.00079\n",
      "Epoch 4 (train)4.3s: train loss = 0.23555 = (mf)0.23457 + (embed)0.00098\n",
      "Epoch 5 (train)4.3s + (eval)0.2s: train loss = 0.22679 = (mf)0.22568 + (embed)0.00111, recall = 0.16383, ndcg = 0.35578, precision = 0.30795, map = 0.09480\n",
      "Epoch 6 (train)4.3s: train loss = 0.21972 = (mf)0.21849 + (embed)0.00122\n",
      "Epoch 7 (train)4.3s: train loss = 0.21002 = (mf)0.20868 + (embed)0.00135\n",
      "Epoch 8 (train)4.3s: train loss = 0.19879 = (mf)0.19730 + (embed)0.00149\n",
      "Epoch 9 (train)4.3s: train loss = 0.18909 = (mf)0.18745 + (embed)0.00164\n",
      "Epoch 10 (train)4.4s + (eval)0.2s: train loss = 0.17941 = (mf)0.17761 + (embed)0.00181, recall = 0.18276, ndcg = 0.39648, precision = 0.34252, map = 0.11161\n",
      "Epoch 11 (train)4.4s: train loss = 0.17284 = (mf)0.17088 + (embed)0.00196\n",
      "Epoch 12 (train)4.4s: train loss = 0.17123 = (mf)0.16914 + (embed)0.00209\n",
      "Epoch 13 (train)4.3s: train loss = 0.16664 = (mf)0.16443 + (embed)0.00221\n",
      "Epoch 14 (train)4.4s: train loss = 0.16880 = (mf)0.16648 + (embed)0.00231\n",
      "Epoch 15 (train)4.3s + (eval)0.2s: train loss = 0.16310 = (mf)0.16070 + (embed)0.00240, recall = 0.19429, ndcg = 0.40640, precision = 0.35217, map = 0.11830\n",
      "Training time: 65.8775s\n",
      "Ranking prediction time: 0.0693s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:recommenders.datasets.download_utils:Downloading https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
      "100%|██████████| 5.78k/5.78k [00:00<00:00, 20.8kKB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Movielens 1m: (1000209, 4)\n",
      "\n",
      "Computing als algorithm on Movielens 1m\n",
      "Training time: 5.6175s\n",
      "Rating prediction time: 0.0266s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking prediction time: 0.0620s\n",
      "\n",
      "Computing svd algorithm on Movielens 1m\n",
      "Training time: 43.7867s\n",
      "Rating prediction time: 3.1679s\n",
      "Ranking prediction time: 198.7200s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Collecting user affinity matrix\n",
      "INFO:root:Calculating time-decayed affinities\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing sar algorithm on Movielens 1m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Creating index columns\n",
      "INFO:root:Building user affinity sparse matrix\n",
      "INFO:root:Calculating item co-occurrence\n",
      "INFO:root:Calculating item similarity\n",
      "INFO:root:Using jaccard based similarity\n",
      "INFO:root:Done training\n",
      "INFO:root:Calculating recommendation scores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 3.3929s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Removing seen items\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking prediction time: 2.4481s\n",
      "\n",
      "Computing ncf algorithm on Movielens 1m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:recommenders.models.ncf.dataset:Indexing ./df_train.csv ...\n",
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 10 [45.82s]: train_loss = 0.296152 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 686.9924s\n",
      "Ranking prediction time: 51.7218s\n",
      "\n",
      "Computing fastai algorithm on Movielens 1m\n",
      "Training time: 680.4962s\n",
      "Rating prediction time: 0.3984s\n",
      "Ranking prediction time: 47.4308s\n",
      "\n",
      "Computing bpr algorithm on Movielens 1m\n",
      "Training time: 65.8879s\n",
      "Ranking prediction time: 50.5751s\n",
      "\n",
      "Computing bivae algorithm on Movielens 1m\n",
      "Training time: 219.3037s\n",
      "Ranking prediction time: 28.6644s\n",
      "\n",
      "Computing lightgcn algorithm on Movielens 1m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/recommenders/models/deeprec/DataModel/ImplicitCF.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = train if test is None else train.append(test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n",
      "Epoch 1 (train)407.1s: train loss = 0.34797 = (mf)0.34738 + (embed)0.00059\n",
      "Epoch 2 (train)406.8s: train loss = 0.27672 = (mf)0.27538 + (embed)0.00133\n",
      "Epoch 3 (train)406.3s: train loss = 0.22676 = (mf)0.22449 + (embed)0.00227\n",
      "Epoch 4 (train)406.4s: train loss = 0.20416 = (mf)0.20120 + (embed)0.00296\n",
      "Epoch 5 (train)406.8s + (eval)3.8s: train loss = 0.18869 = (mf)0.18510 + (embed)0.00359, recall = 0.12050, ndcg = 0.36984, precision = 0.33454, map = 0.07163\n",
      "Epoch 6 (train)406.1s: train loss = 0.17532 = (mf)0.17113 + (embed)0.00420\n",
      "Epoch 7 (train)410.3s: train loss = 0.16492 = (mf)0.16014 + (embed)0.00478\n",
      "Epoch 8 (train)411.4s: train loss = 0.15507 = (mf)0.14971 + (embed)0.00536\n",
      "Epoch 9 (train)410.9s: train loss = 0.14920 = (mf)0.14328 + (embed)0.00592\n",
      "Epoch 10 (train)407.1s + (eval)3.8s: train loss = 0.14199 = (mf)0.13554 + (embed)0.00645, recall = 0.13939, ndcg = 0.40932, precision = 0.37111, map = 0.08446\n",
      "Epoch 11 (train)405.9s: train loss = 0.13644 = (mf)0.12949 + (embed)0.00695\n",
      "Epoch 12 (train)406.4s: train loss = 0.13220 = (mf)0.12476 + (embed)0.00744\n",
      "Epoch 13 (train)408.0s: train loss = 0.12843 = (mf)0.12053 + (embed)0.00790\n",
      "Epoch 14 (train)409.7s: train loss = 0.12483 = (mf)0.11649 + (embed)0.00834\n",
      "Epoch 15 (train)408.6s + (eval)3.8s: train loss = 0.12185 = (mf)0.11310 + (embed)0.00875, recall = 0.14365, ndcg = 0.41609, precision = 0.37742, map = 0.08720\n",
      "Training time: 6129.2162s\n",
      "Ranking prediction time: 2.1656s\n",
      "\n",
      "Computation finished\n",
      "CPU times: user 2h 37min 44s, sys: 9min 4s, total: 2h 46min 48s\n",
      "Wall time: 2h 35min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# For each data size and each algorithm, a recommender is evaluated. \n",
    "cols = [\"Data\", \"Algo\", \"K\", \"Train time (s)\", \"Predicting time (s)\", \"RMSE\", \"MAE\", \"R2\", \"Explained Variance\", \"Recommending time (s)\", \"MAP\", \"nDCG@k\", \"Precision@k\", \"Recall@k\"]\n",
    "df_results = pd.DataFrame(columns=cols)\n",
    "\n",
    "for data_size in data_sizes:\n",
    "    # Load the dataset\n",
    "    df = movielens.load_pandas_df(\n",
    "        size=data_size,\n",
    "        header=[DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL]\n",
    "    )\n",
    "    print(\"Size of Movielens {}: {}\".format(data_size, df.shape))\n",
    "    \n",
    "    # Split the dataset\n",
    "    df_train, df_test = python_stratified_split(df,\n",
    "                                                ratio=0.75, \n",
    "                                                min_rating=1, \n",
    "                                                filter_by=\"item\", \n",
    "                                                col_user=DEFAULT_USER_COL, \n",
    "                                                col_item=DEFAULT_ITEM_COL\n",
    "                                                )\n",
    "   \n",
    "    # Loop through the algos\n",
    "    for algo in algorithms:\n",
    "        print(f\"\\nComputing {algo} algorithm on Movielens {data_size}\")\n",
    "          \n",
    "        # Data prep for training set\n",
    "        train = prepare_training_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\n",
    "        \n",
    "        # Get model parameters\n",
    "        model_params = params[algo]\n",
    "          \n",
    "        # Train the model\n",
    "        model, time_train = trainer[algo](model_params, train)\n",
    "        print(f\"Training time: {time_train}s\")\n",
    "                \n",
    "        # Predict and evaluate\n",
    "        train, test = prepare_metrics_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\n",
    "        \n",
    "        if \"rating\" in metrics[algo]:   \n",
    "            # Predict for rating\n",
    "            preds, time_rating = rating_predictor[algo](model, test)\n",
    "            print(f\"Rating prediction time: {time_rating}s\")\n",
    "            \n",
    "            # Evaluate for rating\n",
    "            ratings = rating_evaluator[algo](test, preds)\n",
    "        else:\n",
    "            ratings = None\n",
    "            time_rating = np.nan\n",
    "        \n",
    "        if \"ranking\" in metrics[algo]:\n",
    "            # Predict for ranking\n",
    "            top_k_scores, time_ranking = ranking_predictor[algo](model, test, train)\n",
    "            print(f\"Ranking prediction time: {time_ranking}s\")\n",
    "            \n",
    "            # Evaluate for rating\n",
    "            rankings = ranking_evaluator[algo](test, top_k_scores, DEFAULT_K)\n",
    "        else:\n",
    "            rankings = None\n",
    "            time_ranking = np.nan\n",
    "            \n",
    "        # Record results\n",
    "        summary = generate_summary(data_size, algo, DEFAULT_K, time_train, time_rating, ratings, time_ranking, rankings)\n",
    "        df_results.loc[df_results.shape[0] + 1] = summary\n",
    "        \n",
    "print(\"\\nComputation finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Algo</th>\n",
       "      <th>K</th>\n",
       "      <th>Train time (s)</th>\n",
       "      <th>Predicting time (s)</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Explained Variance</th>\n",
       "      <th>Recommending time (s)</th>\n",
       "      <th>MAP</th>\n",
       "      <th>nDCG@k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100k</td>\n",
       "      <td>als</td>\n",
       "      <td>10</td>\n",
       "      <td>7.2316</td>\n",
       "      <td>0.0861</td>\n",
       "      <td>0.966505</td>\n",
       "      <td>0.752611</td>\n",
       "      <td>0.253207</td>\n",
       "      <td>0.249371</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.006217</td>\n",
       "      <td>0.053377</td>\n",
       "      <td>0.054825</td>\n",
       "      <td>0.020420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100k</td>\n",
       "      <td>svd</td>\n",
       "      <td>10</td>\n",
       "      <td>4.3036</td>\n",
       "      <td>0.2510</td>\n",
       "      <td>0.938681</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.291967</td>\n",
       "      <td>0.291971</td>\n",
       "      <td>14.3849</td>\n",
       "      <td>0.012873</td>\n",
       "      <td>0.095930</td>\n",
       "      <td>0.091198</td>\n",
       "      <td>0.032783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100k</td>\n",
       "      <td>sar</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>0.113028</td>\n",
       "      <td>0.388321</td>\n",
       "      <td>0.333828</td>\n",
       "      <td>0.183179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100k</td>\n",
       "      <td>ncf</td>\n",
       "      <td>10</td>\n",
       "      <td>52.1639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6720</td>\n",
       "      <td>0.105227</td>\n",
       "      <td>0.394226</td>\n",
       "      <td>0.349311</td>\n",
       "      <td>0.179064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100k</td>\n",
       "      <td>fastai</td>\n",
       "      <td>10</td>\n",
       "      <td>78.5280</td>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.941035</td>\n",
       "      <td>0.742262</td>\n",
       "      <td>0.288411</td>\n",
       "      <td>0.290805</td>\n",
       "      <td>3.0010</td>\n",
       "      <td>0.025521</td>\n",
       "      <td>0.147204</td>\n",
       "      <td>0.130753</td>\n",
       "      <td>0.054545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100k</td>\n",
       "      <td>bpr</td>\n",
       "      <td>10</td>\n",
       "      <td>6.1744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.9153</td>\n",
       "      <td>0.129946</td>\n",
       "      <td>0.437411</td>\n",
       "      <td>0.383669</td>\n",
       "      <td>0.209318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100k</td>\n",
       "      <td>bivae</td>\n",
       "      <td>10</td>\n",
       "      <td>22.0689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5642</td>\n",
       "      <td>0.147895</td>\n",
       "      <td>0.478870</td>\n",
       "      <td>0.415164</td>\n",
       "      <td>0.221764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100k</td>\n",
       "      <td>lightgcn</td>\n",
       "      <td>10</td>\n",
       "      <td>65.8775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0693</td>\n",
       "      <td>0.118297</td>\n",
       "      <td>0.406401</td>\n",
       "      <td>0.352174</td>\n",
       "      <td>0.194290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1m</td>\n",
       "      <td>als</td>\n",
       "      <td>10</td>\n",
       "      <td>5.6175</td>\n",
       "      <td>0.0266</td>\n",
       "      <td>0.860085</td>\n",
       "      <td>0.679199</td>\n",
       "      <td>0.412694</td>\n",
       "      <td>0.406956</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.023573</td>\n",
       "      <td>0.029551</td>\n",
       "      <td>0.009647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1m</td>\n",
       "      <td>svd</td>\n",
       "      <td>10</td>\n",
       "      <td>43.7867</td>\n",
       "      <td>3.1679</td>\n",
       "      <td>0.883017</td>\n",
       "      <td>0.695366</td>\n",
       "      <td>0.374910</td>\n",
       "      <td>0.374911</td>\n",
       "      <td>198.7200</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>0.089320</td>\n",
       "      <td>0.082856</td>\n",
       "      <td>0.021582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1m</td>\n",
       "      <td>sar</td>\n",
       "      <td>10</td>\n",
       "      <td>3.3929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4481</td>\n",
       "      <td>0.066214</td>\n",
       "      <td>0.313502</td>\n",
       "      <td>0.279692</td>\n",
       "      <td>0.111135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1m</td>\n",
       "      <td>ncf</td>\n",
       "      <td>10</td>\n",
       "      <td>686.9924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.7218</td>\n",
       "      <td>0.066133</td>\n",
       "      <td>0.355609</td>\n",
       "      <td>0.323787</td>\n",
       "      <td>0.112756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1m</td>\n",
       "      <td>fastai</td>\n",
       "      <td>10</td>\n",
       "      <td>680.4962</td>\n",
       "      <td>0.3984</td>\n",
       "      <td>0.874521</td>\n",
       "      <td>0.695453</td>\n",
       "      <td>0.386880</td>\n",
       "      <td>0.389455</td>\n",
       "      <td>47.4308</td>\n",
       "      <td>0.026048</td>\n",
       "      <td>0.184098</td>\n",
       "      <td>0.167915</td>\n",
       "      <td>0.055359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1m</td>\n",
       "      <td>bpr</td>\n",
       "      <td>10</td>\n",
       "      <td>65.8879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.5751</td>\n",
       "      <td>0.083816</td>\n",
       "      <td>0.393066</td>\n",
       "      <td>0.359318</td>\n",
       "      <td>0.142690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1m</td>\n",
       "      <td>bivae</td>\n",
       "      <td>10</td>\n",
       "      <td>219.3037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.6644</td>\n",
       "      <td>0.094853</td>\n",
       "      <td>0.435701</td>\n",
       "      <td>0.397449</td>\n",
       "      <td>0.152546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1m</td>\n",
       "      <td>lightgcn</td>\n",
       "      <td>10</td>\n",
       "      <td>6129.2162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.1656</td>\n",
       "      <td>0.087202</td>\n",
       "      <td>0.416088</td>\n",
       "      <td>0.377423</td>\n",
       "      <td>0.143652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Data      Algo   K Train time (s) Predicting time (s)      RMSE       MAE  \\\n",
       "1   100k       als  10         7.2316              0.0861  0.966505  0.752611   \n",
       "2   100k       svd  10         4.3036              0.2510  0.938681  0.742690   \n",
       "3   100k       sar  10         0.3554                 NaN       NaN       NaN   \n",
       "4   100k       ncf  10        52.1639                 NaN       NaN       NaN   \n",
       "5   100k    fastai  10        78.5280              0.0444  0.941035  0.742262   \n",
       "6   100k       bpr  10         6.1744                 NaN       NaN       NaN   \n",
       "7   100k     bivae  10        22.0689                 NaN       NaN       NaN   \n",
       "8   100k  lightgcn  10        65.8775                 NaN       NaN       NaN   \n",
       "9     1m       als  10         5.6175              0.0266  0.860085  0.679199   \n",
       "10    1m       svd  10        43.7867              3.1679  0.883017  0.695366   \n",
       "11    1m       sar  10         3.3929                 NaN       NaN       NaN   \n",
       "12    1m       ncf  10       686.9924                 NaN       NaN       NaN   \n",
       "13    1m    fastai  10       680.4962              0.3984  0.874521  0.695453   \n",
       "14    1m       bpr  10        65.8879                 NaN       NaN       NaN   \n",
       "15    1m     bivae  10       219.3037                 NaN       NaN       NaN   \n",
       "16    1m  lightgcn  10      6129.2162                 NaN       NaN       NaN   \n",
       "\n",
       "          R2  Explained Variance Recommending time (s)       MAP    nDCG@k  \\\n",
       "1   0.253207            0.249371                0.0869  0.006217  0.053377   \n",
       "2   0.291967            0.291971               14.3849  0.012873  0.095930   \n",
       "3        NaN                 NaN                0.0881  0.113028  0.388321   \n",
       "4        NaN                 NaN                3.6720  0.105227  0.394226   \n",
       "5   0.288411            0.290805                3.0010  0.025521  0.147204   \n",
       "6        NaN                 NaN                3.9153  0.129946  0.437411   \n",
       "7        NaN                 NaN                1.5642  0.147895  0.478870   \n",
       "8        NaN                 NaN                0.0693  0.118297  0.406401   \n",
       "9   0.412694            0.406956                0.0620  0.002011  0.023573   \n",
       "10  0.374910            0.374911              198.7200  0.008828  0.089320   \n",
       "11       NaN                 NaN                2.4481  0.066214  0.313502   \n",
       "12       NaN                 NaN               51.7218  0.066133  0.355609   \n",
       "13  0.386880            0.389455               47.4308  0.026048  0.184098   \n",
       "14       NaN                 NaN               50.5751  0.083816  0.393066   \n",
       "15       NaN                 NaN               28.6644  0.094853  0.435701   \n",
       "16       NaN                 NaN                2.1656  0.087202  0.416088   \n",
       "\n",
       "    Precision@k  Recall@k  \n",
       "1      0.054825  0.020420  \n",
       "2      0.091198  0.032783  \n",
       "3      0.333828  0.183179  \n",
       "4      0.349311  0.179064  \n",
       "5      0.130753  0.054545  \n",
       "6      0.383669  0.209318  \n",
       "7      0.415164  0.221764  \n",
       "8      0.352174  0.194290  \n",
       "9      0.029551  0.009647  \n",
       "10     0.082856  0.021582  \n",
       "11     0.279692  0.111135  \n",
       "12     0.323787  0.112756  \n",
       "13     0.167915  0.055359  \n",
       "14     0.359318  0.142690  \n",
       "15     0.397449  0.152546  \n",
       "16     0.377423  0.143652  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b9e8d8274bb2aefc43ff4060bf2aea1a22b531dbbc61ceb737842ea8b3b7c74"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
